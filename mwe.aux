\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{biblatex}
\bibdata{mwe-blx,/home/marius/Dokumenter/MyLibrary}
\citation{biblatex-control}
\abx@aux@sortscheme{nty}
\abx@aux@refcontext{nty/global/}
\@writefile{toc}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lof}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\@writefile{lot}{\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax }
\select@language{english}
\@writefile{toc}{\defcounter {refsection}{0}\relax }\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\defcounter {refsection}{0}\relax }\@writefile{lot}{\select@language{english}}
\newlabel{eq:varcov}{{1}{2}{}{equation.0.1}{}}
\newlabel{eq:block}{{2}{2}{}{equation.0.2}{}}
\newlabel{prop:rho}{{1}{2}{}{theorem.0.1}{}}
\newlabel{eq:rate}{{3}{2}{}{equation.0.3}{}}
\newlabel{prop:diff}{{1}{2}{}{equation.0.3}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A simple implementation for \texttt  {python}. In step (1) we initialize some variables. \texttt  {n} is the length of the ovservation vector \texttt  {x} containing $X_1^{0}, X_2^{0}, \cdots  , X_{2^d}^{0}$. \texttt  {mu} is the mean of \texttt  {x} which is required when we for each blocking iteration compute the auto-covariance \texttt  {gamma}. The array \texttt  {s} will contain the variances for each blocking iteration. In step (2), we for each blocking iteration \texttt  {i} compute the associated \texttt  {gamma[i]} and \texttt  {s[i]} and perform a blocking transformation. In step (3) we cumulatively sum the test observator $Z_k$. In step (4) we save an array of at least length \texttt  {d} which contains all the quantiles from the chi square distribution. In step (5) we perform the hypothesis test to determine the appropriate $k$ and finally (6) compute the answer at the iteration number $k$.\relax }}{3}{figure.caption.1}}
\citation{flyvbjerg_error_1989}
\abx@aux@cite{flyvbjerg_error_1989}
\abx@aux@segm{0}{0}{flyvbjerg_error_1989}
\newlabel{eq:epsilonM}{{4}{4}{}{equation.0.4}{}}
\newlabel{eq:TM}{{5}{4}{}{equation.0.5}{}}
\newlabel{lemma:k}{{}{4}{}{equation.0.5}{}}
\@writefile{lof}{\defcounter {refsection}{0}\relax }\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Relative error squared of two autoregressive models versus observations per time autocorrelation time-constant. There is exponential convergence rate for two vastly different correlation structures. AR(1) autocorrelation is positive with exponential decay whilst AR(2) is oscillatory with exponential decay. The processes were distributed vastly different. They were Gamma(1,1) and Standard Normal respectively. The method was insensitive to the distribution of the observations ($p = 0.895$) [sjekk dette]. It is apparant that the first digit of the method was correct for $n = 50\tau $, and two digits correct for $n = 500\tau $. The mean relative errors $\mu $ were modelled by gamma regression, $\qopname  \relax o{log}\mu = \beta _0 + \beta _1 x$. Deviance explained was 50.65\% and 65.39\% respectively on 6078 degrees of freedom. Dashed lines give 95\% confidence intervals of the means.\relax }}{5}{figure.caption.2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:figure1}{{2}{5}{Relative error squared of two autoregressive models versus observations per time autocorrelation time-constant. There is exponential convergence rate for two vastly different correlation structures. AR(1) autocorrelation is positive with exponential decay whilst AR(2) is oscillatory with exponential decay. The processes were distributed vastly different. They were Gamma(1,1) and Standard Normal respectively. The method was insensitive to the distribution of the observations ($p = 0.895$) [sjekk dette]. It is apparant that the first digit of the method was correct for $n = 50\tau $, and two digits correct for $n = 500\tau $. The mean relative errors $\mu $ were modelled by gamma regression, $\log \mu = \beta _0 + \beta _1 x$. Deviance explained was 50.65\% and 65.39\% respectively on 6078 degrees of freedom. Dashed lines give 95\% confidence intervals of the means.\relax }{figure.caption.2}{}}
\newlabel{eq:rate}{{6}{6}{}{equation.0.6}{}}
\newlabel{prop:diff}{{}{6}{}{equation.0.6}{}}
\newlabel{eq:functional}{{7}{6}{}{equation.0.7}{}}
\newlabel{eq:epsilonkpp}{{8}{6}{}{equation.0.8}{}}
\newlabel{eq:sumB}{{9}{6}{}{equation.0.9}{}}
\newlabel{eq:differencesum}{{10}{7}{}{equation.0.10}{}}
\newlabel{eq:nsum}{{11}{7}{}{equation.0.11}{}}
\newlabel{eq:sumsum}{{12}{7}{}{equation.0.12}{}}
\newlabel{eq:hypothesis}{{13}{9}{}{equation.0.13}{}}
\newlabel{prop:sequence}{{3}{9}{}{prop.3}{}}
\newlabel{prop:sigmahat}{{2}{9}{}{lemma.2}{}}
\newlabel{eq:epsilon}{{14}{10}{}{equation.0.14}{}}
\newlabel{eq:T}{{15}{10}{}{equation.0.15}{}}
\newlabel{eq:errorestimate}{{16}{11}{}{equation.0.16}{}}
\newlabel{eq:subdiagonal}{{17}{11}{}{equation.0.17}{}}
